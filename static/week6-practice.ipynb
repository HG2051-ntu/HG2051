{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "\n",
    "This week is about getting data into Python from external sources, such as files on your computer or online. When working with these kinds of sources, we need to understand **character encodings** and **streams**. This week we will also cover **string formatting**, as it is useful when writing to files or to the terminal. Additionally, various Python libraries have been developed to handle different filetypes - we will use the `pandas` library to import/modify/export spreadsheet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  # make sure NLTK is installed and loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode\n",
    "\n",
    "Every character displayed by your computer is assigned a number. Before, each character set (e.g., for a language) chose different numbers for the characters, but this made it difficult to have documents with more than one character set. [Unicode](https://unicode.org/) is the modern standard for assigning these numbers, and it is one giant table comprising all the known characters, including some non-language characters (ü•≥ü¶•üå§...). In Python, strings are \"pure\" sequences of codepoints. You can find the codepoint (as an integer) of a character with Python's `ord()` function, and the character for a codepoint with the `chr()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ü¶•'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(129445)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice these two functions are used rarely, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings\n",
    "\n",
    "Whenever a unicode string needs to be stored or transmitted outside of Python it must be encoded into a sequence of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe3\\x81\\x82'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'„ÅÇ'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, bytes can be decoded to strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„ÅÇ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'\\xe3\\x81\\x82'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `bytes` objects (the strings prefixed with `b`) use escape sequences to represent the bytes, such as `\\xe3` which represents the bits `1110 0011` (note: you do not need to know this conversion). Python also accepts escape sequences in regular strings, but numbers do not represent UTF-8 or some other encoding, but the numeric value of the codepoint (you do not need to learn these escapes, just recognize that `\\x`, `\\u` and `\\U` followed by 2, 4, or 8 hexadecimal digits (0123456789ABCDEF) is a unicode escape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„ÅÇ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\u3042'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: If you want to find out the decimal value of the hexadecimal number, use the `int()` function with a base of 16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12354"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('3042', 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can get back the hexadecimal version with `hex()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x3042'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(12354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to encode something not representable in the target encoding, you'll get an error. In this case, the letter '√©' is not part of the `ascii` encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\xe9' in position 3: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39m'\u001b[39;49m\u001b[39mcaf√©\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xe9' in position 3: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "'caf√©'.encode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell Python what to do in case of errors, such as ignoring them (note that the letter doesn't appear in the output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'caf√©'.encode('ascii', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a string in Python, you have the entire contents and you can query its length or access any character at once. When you're working with *streams*, however, you only get a small slice, or window, at a time. This is useful when the data is too large to fit into memory (like a dump of all of Wikipedia), or something that is slow to download.\n",
    "\n",
    "Here we will download the text of a book from Project Gutenberg (not using the NLTK):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# urlopen() returns a stream, but then we call .read(), which fetches the whole thing.\n",
    "# The result is a bytes object, not str.\n",
    "bytestring = urllib.request.urlopen('http://gutenberg.org/files/13083/13083-0.txt').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bytestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the language, the data may not be very readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xc3\\xbastavu pro psychologii a v\\xc3\\xbdchovu robot\\xc5\\xaf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytestring[1004:1046]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to decode it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = bytestring.decode('utf-8')\n",
    "type(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the string (if we could read Czech). Note that the indices of the bytestring don't always line up with those of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'√∫stavu pro psychologii a v√Ωchovu robot≈Ø'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[974:1013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read and write files on disk using `open()`. Let's write the downloaded bytes directly to disk using `open()`'s `wb` (\"write bytes\") mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myfile.txt', 'wb') as f:\n",
    "    f.write(bytestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now confirm that we have written the file. You may need to change the encoding from `utf-8` to `utf-8-sig` on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook, R.U.R., by Karel ƒåapek\\n\\n\\nThis eBook is for the use of anyone anywhere '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('myfile.txt', encoding='utf-8') as f:\n",
    "    string = f.read()\n",
    "string[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing bytes directly, if you have the decoded string you can write in \"text\" mode (`wt`, or just `w`). In this case, it's best to specify your desired encoding. Also note that instead of `f.write(bytestring)`, you can use `print(string, file=f)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myfile2.txt', 'wt', encoding='utf-8') as f:\n",
    "    print(string, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Formatting\n",
    "\n",
    "When printing to the terminal or writing to disk, sometimes it helps to format the strings so they are more legible or so they follow a particular file format. The `str.format()` method or \"f-strings\" are two common ways to do so (see this week's reading for explanation of these).\n",
    "\n",
    "Write some code that takes a string and prints a table of each letter found in the string with its frequency. The frequency should be right aligned so number columns (ones, tens, etc.) line up. Don't use NLTK's `nltk.FreqDist.tabulate()` method, but you may use `nltk.FreqDist` to get the frequency information. You may choose to filter out non-letter characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall we can get the frequency distribution of a sequence (of words, or characters, etc.) with nltk.FreqDist\n",
    "import nltk\n",
    "with open('myfile.txt') as f:\n",
    "    # `f.read()` returns the full string of the file\n",
    "    # `if c.isalpha()` only keeps alphabetic characters (optional)\n",
    "    fd = nltk.FreqDist(c for c in f.read() if c.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'e': 10007, 'o': 7985, 'a': 6454, 'n': 6285, 't': 6010, 'l': 4945, 'i': 4758, 's': 4365, 'r': 3723, 'm': 3482, ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our table, we can use a fixed width between the character and the count, but here I first calculate the largest frequency then find its width when it is a string. This is the widest number that we will display. (This step is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = max(fd.values())\n",
    "width = len(str(maximum)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we go over each letter in most-common-first order, then print the letter, a tab character (`\\t`), then the count right aligned in a span using the width we just calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\t10007\n",
      "o\t 7985\n",
      "a\t 6454\n",
      "n\t 6285\n",
      "t\t 6010\n",
      "l\t 4945\n",
      "i\t 4758\n",
      "s\t 4365\n",
      "r\t 3723\n",
      "m\t 3482\n",
      "d\t 3119\n",
      "u\t 3050\n",
      "v\t 2840\n",
      "k\t 2324\n",
      "h\t 2198\n",
      "c\t 2187\n",
      "y\t 2076\n",
      "j\t 2027\n",
      "p\t 2000\n",
      "√≠\t 1930\n",
      "√°\t 1922\n",
      "b\t 1677\n",
      "ƒõ\t 1270\n",
      "z\t 1095\n",
      "≈æ\t  941\n",
      "H\t  894\n",
      "≈°\t  774\n",
      "≈ô\t  717\n",
      "D\t  699\n",
      "ƒç\t  693\n",
      "P\t  610\n",
      "A\t  544\n",
      "√©\t  520\n",
      "R\t  481\n",
      "N\t  474\n",
      "√Ω\t  433\n",
      "f\t  366\n",
      "G\t  362\n",
      "g\t  358\n",
      "T\t  352\n",
      "J\t  299\n",
      "≈Ø\t  287\n",
      "B\t  263\n",
      "w\t  256\n",
      "S\t  236\n",
      "q\t  210\n",
      "V\t  201\n",
      "C\t  194\n",
      "F\t  192\n",
      "M\t  173\n",
      "O\t  163\n",
      "U\t  149\n",
      "K\t  130\n",
      "E\t  128\n",
      "ƒè\t  109\n",
      "I\t  108\n",
      "Z\t  107\n",
      "L\t   90\n",
      "≈•\t   67\n",
      "≈à\t   57\n",
      "√∫\t   42\n",
      "√≥\t   35\n",
      "x\t   33\n",
      "≈ò\t   30\n",
      "Y\t   29\n",
      "ƒå\t   24\n",
      "≈Ω\t   24\n",
      "W\t   16\n",
      "√ì\t   14\n",
      "≈†\t    9\n",
      "√ö\t    5\n",
      "√ç\t    5\n",
      "ƒö\t    3\n",
      "X\t    2\n",
      "≈§\t    1\n",
      "√â\t    1\n",
      "Q\t    1\n"
     ]
    }
   ],
   "source": [
    "for c, count in fd.most_common():\n",
    "    # here I use f-string formatting. The same could be done with:\n",
    "    # print('{c}\\t{count:>{width}}'.format(c=c, count=count, width=width))\n",
    "    print(f'{c}\\t{count:>{width}}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with non-text files\n",
    "\n",
    "The [Pandas](https://pandas.pydata.org/) library makes it easy to work with both CSV/TSV and XLSX file types. We will convert the frequency distribution we made from our file into a `DataFrame`.\n",
    "\n",
    "(if you get a \"module not found\" error, you need to `pip install` the module in your virtual environment via your terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  characters  numbers\n",
      "0          T      352\n",
      "1          h     2198\n",
      "2          e    10007\n",
      "3          P      610\n",
      "4          r     3723\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create lists from the keys and values in the dict (how would you rewrite this as a list comprehension?)\n",
    "chars, nums = [], []\n",
    "for k, v in fd.items():\n",
    "    chars.append(k)\n",
    "    nums.append(v)\n",
    "\n",
    "# we instantiate an empty dataframe here\n",
    "df = pd.DataFrame()\n",
    "# we create two new column headers, populating the columns with the two lists\n",
    "df['characters'], df['numbers'] = chars, nums\n",
    "# then we view the first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a dataframe, Pandas automatically populates the \"index\" value on the left hand side, which you can then use to refer to the row. Dataframes resemble lists and dicts, in that you can get their length (number of rows), you can perform operations on them, you can get slices from them, and you can convert them to/from lists/dicts. Think of a dataframe as a collection of lists where either the index or the header can be the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "  characters  numbers  divided by 2\n",
      "0          T      352         176.0\n",
      "1          h     2198        1099.0\n",
      "2          e    10007        5003.5\n",
      "3          P      610         305.0\n",
      "4          r     3723        1861.5\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df['divided by 2'] = df['numbers']/2\n",
    "print(df.head())\n",
    "\n",
    "charlist = df['characters'].tolist() # make a list from the 'characters' column\n",
    "if charlist == chars: # is this the same as the list we created earlier?\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1\n",
      "0  T    352\n",
      "1  h   2198\n",
      "2  e  10007\n",
      "3  P    610\n",
      "4  r   3723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'T': 352,\n",
       " 'h': 2198,\n",
       " 'e': 10007,\n",
       " 'P': 610,\n",
       " 'r': 3723,\n",
       " 'o': 7985,\n",
       " 'j': 2027,\n",
       " 'c': 2187,\n",
       " 't': 6010,\n",
       " 'G': 362,\n",
       " 'u': 3050,\n",
       " 'n': 6285,\n",
       " 'b': 1677,\n",
       " 'g': 358,\n",
       " 'B': 263,\n",
       " 'k': 2324,\n",
       " 'R': 481,\n",
       " 'U': 149,\n",
       " 'y': 2076,\n",
       " 'K': 130,\n",
       " 'a': 6454,\n",
       " 'l': 4945,\n",
       " 'ƒå': 24,\n",
       " 'p': 2000,\n",
       " 'i': 4758,\n",
       " 's': 4365,\n",
       " 'f': 366,\n",
       " 'w': 256,\n",
       " 'd': 3119,\n",
       " 'm': 3482,\n",
       " 'v': 2840,\n",
       " 'Y': 29,\n",
       " 'L': 90,\n",
       " 'A': 544,\n",
       " 'D': 699,\n",
       " 'C': 194,\n",
       " 'z': 1095,\n",
       " 'F': 192,\n",
       " 'S': 236,\n",
       " 'O': 163,\n",
       " 'H': 894,\n",
       " 'E': 128,\n",
       " 'J': 299,\n",
       " 'N': 474,\n",
       " 'W': 16,\n",
       " 'x': 33,\n",
       " 'M': 173,\n",
       " '√≠': 1930,\n",
       " '≈ô': 717,\n",
       " 'ƒõ': 1270,\n",
       " '√°': 1922,\n",
       " '√Ω': 433,\n",
       " '≈Ø': 287,\n",
       " 'I': 108,\n",
       " '≈æ': 941,\n",
       " '√©': 520,\n",
       " '√∫': 42,\n",
       " 'ƒç': 693,\n",
       " 'q': 210,\n",
       " '≈°': 774,\n",
       " 'V': 201,\n",
       " '√ö': 5,\n",
       " 'ƒè': 109,\n",
       " 'Z': 107,\n",
       " '√≥': 35,\n",
       " '≈Ω': 24,\n",
       " '≈à': 57,\n",
       " '≈†': 9,\n",
       " '≈§': 1,\n",
       " '≈•': 67,\n",
       " '√ì': 14,\n",
       " '≈ò': 30,\n",
       " 'ƒö': 3,\n",
       " '√ç': 5,\n",
       " '√â': 1,\n",
       " 'X': 2,\n",
       " 'Q': 1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can create a dataframe directly from our frequency dict\n",
    "df = pd.DataFrame.from_dict(fd.items()) # you must use `.items()` here\n",
    "print(df.head()) # notice that the column headers are integers `0` and `1` by default\n",
    "# we can create a dictionary from our dataframe, using the first column as the index (key) and the second as the value\n",
    "newfd = df.set_index(0)[1].to_dict()\n",
    "newfd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write this data to a file in CSV or XLSX format using Pandas. To work with XLSX you may need to install the `openpyxl` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['characters', 'numbers']\n",
      "  characters  numbers\n",
      "0          T      352\n",
      "1          h     2198\n",
      "2          e    10007\n",
      "3          P      610\n",
      "4          r     3723\n",
      "   Unnamed: 0 characters  numbers\n",
      "0           0          T      352\n",
      "1           1          h     2198\n",
      "2           2          e    10007\n",
      "3           3          P      610\n",
      "4           4          r     3723\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns)) # see what the column names are\n",
    "df.columns = ['characters', 'numbers'] # set the column names manually\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"myfile.csv\", sep=\"\\t\") # write to csv using tab as delimiter\n",
    "df = pd.read_csv(\"myfile.csv\", delimiter=\"\\t\") # read from csv using tab as delimiter\n",
    "print(df.head()) # notice that it imports the index line as the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  characters  numbers\n",
      "0          T      352\n",
      "1          h     2198\n",
      "2          e    10007\n",
      "3          P      610\n",
      "4          r     3723\n"
     ]
    }
   ],
   "source": [
    "# we can delete the first column by simply excluding it in our list of columns\n",
    "df = df[['characters', 'numbers']]\n",
    "# when we export it (this time as XLSX) we can use the 'index=False' flag to not write the index\n",
    "df.to_excel('myfile.xlsx', index=False) # with excel export/import we don't need a delimiter\n",
    "# then we can import it again\n",
    "xdf = pd.read_excel('myfile.xlsx')\n",
    "print(xdf.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "859938ca7b6a8471053e30db1fb8d68e922ac19bedf325ea06091edab2c59131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
